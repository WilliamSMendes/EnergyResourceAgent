{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sTGQJFDM65W"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y78NtbZ5MRIv"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq32s2kPYLw4"
      },
      "outputs": [],
      "source": [
        "!apt-get install x11-utils > /dev/null 2>&1\n",
        "!pip install pyglet > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9uEoKpWYMVU"
      },
      "outputs": [],
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KSVsz2BpLlQ"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veskV6yhOIX5",
        "outputId": "7a55d83d-249b-4c5f-aaf4-4572f020eded"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
            "2023-07-12 17:52:49.188793: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-12 17:52:50.230529: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#import gym\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P4r_6v-M_Dh"
      },
      "source": [
        "# Load enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8L1xQk8RiL-"
      },
      "outputs": [],
      "source": [
        "enviroment_name = \"CartPole-v1\"\n",
        "env = gym.make(enviroment_name, render_mode=\"human\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "6MM_nZ99SQK5",
        "outputId": "5ed3c514-280a-4358-aa0d-f7ea116f2d49"
      },
      "outputs": [],
      "source": [
        "episodes = 5\n",
        "for episode in range(1, episodes+1):\n",
        "  obs = env.reset()\n",
        "  done = False\n",
        "  score = 0\n",
        "\n",
        "  while not done:\n",
        "    env.render()\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    score += reward\n",
        "\n",
        "  print('Episode: {} Score {}'.format(episode, score))\n",
        "#env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "codqfMNSdZnS",
        "outputId": "12b3e016-7540-41e6-a9b3-385ded26b58c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 0.01988853,  0.22945924,  0.00988458, -0.27532378], dtype=float32),\n",
              " 1.0,\n",
              " False,\n",
              " False,\n",
              " {})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.step(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG84DR0YM_A9"
      },
      "source": [
        "# Understanding the enviroment\n",
        "\n",
        "https://www.gymlibrary.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9-4DietchOj",
        "outputId": "8e7e148f-eafe-4ab2-b771-9182d80039a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Discrete(2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0: Push cart to the left, 1: Push cart to the right\n",
        "env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uCOYLhOchCI",
        "outputId": "764f8e06-dfe8-4be4-8329-bb36c650f0af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr9mJOi2cp4_",
        "outputId": "8aebbd36-5602-4dc3-acf7-2f0c7fe38ba1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qn82KMNcslX",
        "outputId": "69480096-9009-4b48-f620-90ec72c0ec33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-3.4021626e+00,  6.3175695e+37, -1.8298085e-01, -1.8386116e+38],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0: Cart Position, 1: Cart Velocity, 2: Pole Angle, 3: Pole Angular Velocity\n",
        "env.observation_space.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ORVpYrtM--W"
      },
      "source": [
        "# Train an RL model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAeg7lggfX57"
      },
      "source": [
        "* Discrete Single Process: DQN\n",
        "* Discrete Multi Processed: PPO or A2C\n",
        "* Continuous Single Process: SAC or TD3\n",
        "* Continuous Multi Processed: PPO or A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dZta_xgiE-D"
      },
      "outputs": [],
      "source": [
        "# Make the directories\n",
        "# Create a folder named Reinforced_learning and inside create another two folders named Logs and Saved models\n",
        "log_path = os.path.join('Training', 'Logs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fsb_fHOwi7ai",
        "outputId": "10abaca5-5e96-4156-8a45-d8e172eb6d95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/Reinforced_learning/Logs'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xShyfra-jv1o",
        "outputId": "98f21516-eab6-41de-daa9-847767c2f3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-12 17:53:50.316611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-12 17:53:50.354906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-12 17:53:50.355257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-12 17:53:59.646509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-12 17:53:59.646827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-12 17:53:59.647064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-07-12 17:53:59.647241: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-07-12 17:53:59.647282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 13170 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xULjLsr7jFo0",
        "outputId": "7214e308-7959-42be-e373-5127ca001b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(enviroment_name, render_mode=\"human\")\n",
        "env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# Policies types: MlpPolicy, CnnPolicy and MultiInputPolicy\n",
        "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I7xYnqXlyLa"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLlx-cw1M-1B"
      },
      "source": [
        "# Save and reload model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4458HI2YHLi1"
      },
      "outputs": [],
      "source": [
        "PPO_path = os.path.join('Training', 'Saved models', 'PPO_Model_Cartpole')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2BhqHNqHcJE"
      },
      "outputs": [],
      "source": [
        "model.save(PPO_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z71aOfE9HcBU"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDvB_-VKHsbS"
      },
      "outputs": [],
      "source": [
        "model = PPO.load(PPO_path, env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR7sCuZ0IACH"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5E5ksIPNMu4"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX2BBf17Il4Y"
      },
      "source": [
        "* **ep_len_mean:** on average how long a particular episode lasted before done\n",
        "* **ep_rew_mean:** the average reward that the agent accumulated per episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tygGL5rSJceM",
        "outputId": "25ae36a3-20da-467e-90d1-d0cc60589e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO9mrSHzNMpo"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "xW0PjiHYQrdB",
        "outputId": "1520b5d5-5b0c-482b-f190-85db0947231b"
      },
      "outputs": [],
      "source": [
        "episodes = 5\n",
        "for episode in range(1, episodes+1):\n",
        "  obs = env.reset()\n",
        "  done = False\n",
        "  score = 0\n",
        "\n",
        "  while not done:\n",
        "    env.render()\n",
        "    action = model.predict(obs)\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    score += reward\n",
        "\n",
        "  print('Episode: {} Score {}'.format(episode, score))\n",
        "#env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyc0Nw64NMmz"
      },
      "source": [
        "# Viewing logs in Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtabYgKpjlm1"
      },
      "source": [
        "* **Average Reward:** Indicates how well the model perform in the particular enviroment.\n",
        "* **Average Episode Length:** Indicates how long the agent lost in the particular enviroment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o731mSMlUqZI"
      },
      "outputs": [],
      "source": [
        "training_log_path = os.path.join(log_path, 'PPO_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE8BCU8ouSF7"
      },
      "outputs": [],
      "source": [
        "!tensorboard --logdir={training_log_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "audbtMZtkOtY"
      },
      "source": [
        "### If not perform very well:\n",
        "\n",
        "\n",
        "1.   Train for longer\n",
        "2.   Hyperparameter tuning\n",
        "3.   Try Different Algorithms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgA2U8pENQq6"
      },
      "source": [
        "# Adding a callback to the training stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzhWUSxWk1xJ"
      },
      "source": [
        "Can leverage callback functions as part of stable baselines to log out data or save the model under certain conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_jP6hkRlBbI"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jXJypRDmjH2"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join('Training', 'Saved models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGnZCU3MleXz"
      },
      "outputs": [],
      "source": [
        "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
        "eval_callback = EvalCallback(env,\n",
        "                             callback_on_new_best=stop_callback,\n",
        "                             eval_freq=10000,\n",
        "                             best_model_save_path=save_path,\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VSvysKrleSX"
      },
      "outputs": [],
      "source": [
        "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQPTUcDznHRB"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000, callback=eval_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3EI59OvNQoZ"
      },
      "source": [
        "# Changing policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1mOAIF8ntKO"
      },
      "outputs": [],
      "source": [
        "# New architecture\n",
        "net_arch = [dict(pi=[128,128,128,128], vf=[128,128,128,128])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfw671UxnvJo"
      },
      "outputs": [],
      "source": [
        "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path, policy_kwargs={'net_arch':net_arch})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPvFlM7aoa6H"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000, callback=eval_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7pCmNxNQl2"
      },
      "source": [
        "# Using an alternate algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pXB9fXao3rR"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNhBSMkEo6lA"
      },
      "outputs": [],
      "source": [
        "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deuXum3wpDbu"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uENV2W7fpRaP"
      },
      "outputs": [],
      "source": [
        "model.save()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
